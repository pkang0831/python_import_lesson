{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Importing_Practice.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMLfDtWYuh4bnaTxH/Q8ofF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pkang0831/python_import_lesson/blob/gh-pages/Importing_Practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThwYcTSyLKIb"
      },
      "source": [
        "# importing pandas and numpy library\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "# there are few different ways, but the most popular one is read_csv() from pandas library\r\n",
        "path = \"/Bit_Discrep_Data.csv\"\r\n",
        "df = pd.read_csv(path)\r\n",
        "\r\n",
        "# in the dataset, if the header is not available (i.e. column variable name is not \r\n",
        "# available), you would use \"header = None\" as a second argument of this read_csv()\r\n",
        "# instance.\r\n",
        "df = pd.read_csv(path, header=None)\r\n",
        "df = pd.read_csv(path)\r\n",
        "\r\n",
        "# if you have \"read\" the csv data, you can check first 5 rows or first n rows using .head()\r\n",
        "# method. default is first 5 rows. same thing goes for .tail()\r\n",
        "df.head() # first 5 rows, by default if you don't specify the integer argument\r\n",
        "df.head(10) # first 10 rows\r\n",
        "df.tail() # last 5 rows, by default if you don't specify the integer argument\r\n",
        "df.tail(10) # last 10 rows\r\n",
        "\r\n",
        "# let's say that this data does not have any headers.\r\n",
        "df = pd.read_csv(path, header = None)\r\n",
        "df.drop(df.index[0], inplace=True) # don't mind at this stage"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "hJQHjQe9Mu3W",
        "outputId": "9996260e-2099-4500-f2cf-f877dc87b23b"
      },
      "source": [
        "# then this df dataset will contain variable names (column names) as numeric integers. lets add headers to this specific dataset\r\n",
        "headers = ['Date', 'Bit Discrep', 'MILL_OILSAND_MASS', 'P82_OILSAND_MASS',\r\n",
        "       'OPPA contribution', 'OPPB contribution', '85WIC1703', '85WIC2803',\r\n",
        "       '86FROTHORERATIO', '300FROTHORERATIO', 'MM_ORE_BPT_30M', 'SB_BPT_30M']\r\n",
        "print(headers) # check if \"headers\" are correctly assigned\r\n",
        "df.columns = headers\r\n",
        "df.head(5)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Date', 'Bit Discrep', 'MILL_OILSAND_MASS', 'P82_OILSAND_MASS', 'OPPA contribution', 'OPPB contribution', '85WIC1703', '85WIC2803', '86FROTHORERATIO', '300FROTHORERATIO', 'MM_ORE_BPT_30M', 'SB_BPT_30M']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Bit Discrep</th>\n",
              "      <th>MILL_OILSAND_MASS</th>\n",
              "      <th>P82_OILSAND_MASS</th>\n",
              "      <th>OPPA contribution</th>\n",
              "      <th>OPPB contribution</th>\n",
              "      <th>85WIC1703</th>\n",
              "      <th>85WIC2803</th>\n",
              "      <th>86FROTHORERATIO</th>\n",
              "      <th>300FROTHORERATIO</th>\n",
              "      <th>MM_ORE_BPT_30M</th>\n",
              "      <th>SB_BPT_30M</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3/1/2019</td>\n",
              "      <td>19.69791955</td>\n",
              "      <td>9315.664083</td>\n",
              "      <td>9189.952324</td>\n",
              "      <td>44.62%</td>\n",
              "      <td>1.07%</td>\n",
              "      <td>4156.501897</td>\n",
              "      <td>99.96167154</td>\n",
              "      <td>0.860259175</td>\n",
              "      <td>1.014670014</td>\n",
              "      <td>0.737260171</td>\n",
              "      <td>0.74152442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3/2/2019</td>\n",
              "      <td>21.16363808</td>\n",
              "      <td>12350.03547</td>\n",
              "      <td>7052.307331</td>\n",
              "      <td>25.66%</td>\n",
              "      <td>36.66%</td>\n",
              "      <td>3168.569401</td>\n",
              "      <td>4527.271178</td>\n",
              "      <td>0.937038988</td>\n",
              "      <td>1.20513922</td>\n",
              "      <td>0.749594188</td>\n",
              "      <td>0.747536415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3/3/2019</td>\n",
              "      <td>64.19063652</td>\n",
              "      <td>12039.11485</td>\n",
              "      <td>6480.530749</td>\n",
              "      <td>24.94%</td>\n",
              "      <td>37.12%</td>\n",
              "      <td>3002.574613</td>\n",
              "      <td>4468.599288</td>\n",
              "      <td>0.938837379</td>\n",
              "      <td>1.03887856</td>\n",
              "      <td>0.75815843</td>\n",
              "      <td>0.733346353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3/4/2019</td>\n",
              "      <td>17.50700601</td>\n",
              "      <td>9675.460314</td>\n",
              "      <td>8068.956867</td>\n",
              "      <td>0.01%</td>\n",
              "      <td>47.44%</td>\n",
              "      <td>1.000008453</td>\n",
              "      <td>4590.392288</td>\n",
              "      <td>1.000786334</td>\n",
              "      <td>1.122290969</td>\n",
              "      <td>0.740347257</td>\n",
              "      <td>0.742009511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3/5/2019</td>\n",
              "      <td>-15.9997933</td>\n",
              "      <td>10191.72919</td>\n",
              "      <td>4548.687602</td>\n",
              "      <td>0.01%</td>\n",
              "      <td>49.21%</td>\n",
              "      <td>1.000008352</td>\n",
              "      <td>5015.684147</td>\n",
              "      <td>0.996442348</td>\n",
              "      <td>1.15935111</td>\n",
              "      <td>0.743169198</td>\n",
              "      <td>0.720819765</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Date  Bit Discrep  ... MM_ORE_BPT_30M   SB_BPT_30M\n",
              "1  3/1/2019  19.69791955  ...    0.737260171   0.74152442\n",
              "2  3/2/2019  21.16363808  ...    0.749594188  0.747536415\n",
              "3  3/3/2019  64.19063652  ...     0.75815843  0.733346353\n",
              "4  3/4/2019  17.50700601  ...    0.740347257  0.742009511\n",
              "5  3/5/2019  -15.9997933  ...    0.743169198  0.720819765\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtNOv009OlY5"
      },
      "source": [
        "# lets say, in the csv file that we imported, contains non-numeric, not NaN values. how do we replace them? you would use replace() to replace the values.\r\n",
        "df = df.replace('#DIV/0!',np.NaN)\r\n",
        "df = df.replace('#REF!',np.NaN)\r\n",
        "df = df.replace('#VALUE!',np.NaN)\r\n",
        "df = df.replace('#NAME?',np.NaN)\r\n",
        "df = df.replace('#NULL!',np.NaN)\r\n",
        "df = df.replace('#N/A',np.NaN) # We will try to use for loops for this later on.\r\n",
        "\r\n",
        "# When all the values are replaced with NaN, you have few choices:\r\n",
        "\r\n",
        "# 1. Replacing NaN with column averages using replace() method\r\n",
        "# 2. Dropping observation where NaN is contained (mostly will be used in my case) using dropna() method\r\n",
        "\r\n",
        "df = df.dropna(subset=df.columns,axis=0)\r\n",
        "# dropna() function syntax is as follows:\r\n",
        "# dataset.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)\r\n",
        "# axis = 0 means row, 1 means column\r\n",
        "# how = 'any' means if any NA values are present, drop that row or column.\r\n",
        "#       'all' means if all values are NA, drop that row or column.\r\n",
        "# thresh = integer values, required amount of NA to drop that row\r\n",
        "# subset = Labels along other axis to consider, e.g. if you are dropping rows these would be a list of columns to include. [array like]\r\n",
        "# inplace = True or False"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUCDtvOA5Z-e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f320fcdc-b46d-408c-dda5-a79cde186817"
      },
      "source": [
        "# saving dataset\r\n",
        "# after you have completed pre-cleaning step, if you want to save it to other csv, you would use .to_csv() pandas method\r\n",
        "df.to_csv(\"Data.csv\",index=False)\r\n",
        "# Read/Save Other Data Formats\r\n",
        "\r\n",
        "# | Data Formate |        Read       |            Save |\r\n",
        "# | ------------ | :---------------: | --------------: |\r\n",
        "# | csv          |  `pd.read_csv()`  |   `df.to_csv()` |\r\n",
        "# | json         |  `pd.read_json()` |  `df.to_json()` |\r\n",
        "# | excel        | `pd.read_excel()` | `df.to_excel()` |\r\n",
        "# | hdf          |  `pd.read_hdf()`  |   `df.to_hdf()` |\r\n",
        "# | sql          |  `pd.read_sql()`  |   `df.to_sql()` |\r\n",
        "# | ...          |        ...        |             ... |\r\n",
        "\r\n",
        "# reading data types\r\n",
        "# you would use .dtypes method in pandas to see what is the datatype for each variable.\r\n",
        "df.dtypes\r\n",
        "\r\n",
        "# after pre-cleansing step of the dataset, the simplest way of looking at data is by looking at descriptive statistics. you do this by:\r\n",
        "df.describe()\r\n",
        "# then you would see a table that contains all variable's mean, count, stdev, var, 25%, 50%, 75% quantiles, min and max\r\n",
        "# if you include include='all', you would get stats on type object data as well. this describe function excludes NaN values\r\n",
        "df.describe(include='all')\r\n",
        "\r\n",
        "# Another way of looking at the data types or the information of the dataset is .info() method.\r\n",
        "\r\n",
        "df.info()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 592 entries, 1 to 592\n",
            "Data columns (total 12 columns):\n",
            " #   Column             Non-Null Count  Dtype \n",
            "---  ------             --------------  ----- \n",
            " 0   Date               592 non-null    object\n",
            " 1   Bit Discrep        592 non-null    object\n",
            " 2   MILL_OILSAND_MASS  592 non-null    object\n",
            " 3   P82_OILSAND_MASS   592 non-null    object\n",
            " 4   OPPA contribution  592 non-null    object\n",
            " 5   OPPB contribution  592 non-null    object\n",
            " 6   85WIC1703          592 non-null    object\n",
            " 7   85WIC2803          592 non-null    object\n",
            " 8   86FROTHORERATIO    592 non-null    object\n",
            " 9   300FROTHORERATIO   592 non-null    object\n",
            " 10  MM_ORE_BPT_30M     592 non-null    object\n",
            " 11  SB_BPT_30M         592 non-null    object\n",
            "dtypes: object(12)\n",
            "memory usage: 60.1+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLmmjkNjXDAt"
      },
      "source": [
        "# typecasting\r\n",
        "\r\n",
        "# A lot of times, when raw dataset is imported, it contains non-numeric values, non-numeric numeric values (looks like numeric but type object) and etc.\r\n",
        "# There are several different ways of casting the data types, but I will mainly use following 2 methods from pandas:\r\n",
        "# 1 .astype() - you have to use for loops in this case.\r\n",
        "# 2 .to_numeric() - you have to use for loops and use .apply() function, and this apply function will become very handy later on.\r\n",
        "\r\n",
        "# Before we typecast every values to numeric, we know that OPPA contribution and OPPB contribution is in the %. we need to convert that into decimals first\r\n",
        "\r\n",
        "for col in ['OPPA contribution','OPPB contribution']:\r\n",
        "  df[col] = df[col].str.rstrip('%').astype('float') / 100.0\r\n",
        "\r\n",
        "# # 1st method, using .astype():\r\n",
        "for col in df.columns.drop('Date'):\r\n",
        "  df[col] = df[col].astype('float')\r\n",
        "\r\n",
        "# # 2nd method, using .to_numeric():\r\n",
        "for col in df.columns.drop('Date'):\r\n",
        "  df[col] = df[col].apply(pd.to_numeric,errors='coerce')\r\n",
        "\r\n",
        "df['Date'] = df['Date'].apply(pd.to_datetime,errors='coerce')\r\n",
        "\r\n",
        "# in .apply function, lambda will be used, but we will learn this later on \r\n",
        "\r\n",
        "# what I have just used is called 1 line for loop. it is used like\r\n",
        "# for x in array-like[]: df[x] = df[x]...... (actions here)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbeiizCeXLBo",
        "outputId": "e84b5a47-b261-4e68-daa4-2f27c02bed5a"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Date                 datetime64[ns]\n",
              "Bit Discrep                 float64\n",
              "MILL_OILSAND_MASS           float64\n",
              "P82_OILSAND_MASS            float64\n",
              "OPPA contribution           float64\n",
              "OPPB contribution           float64\n",
              "85WIC1703                   float64\n",
              "85WIC2803                   float64\n",
              "86FROTHORERATIO             float64\n",
              "300FROTHORERATIO            float64\n",
              "MM_ORE_BPT_30M              float64\n",
              "SB_BPT_30M                  float64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfte15fzz_2i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}